{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Settings:\n",
    "\n",
    "Directory Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T62.filter.fastq', 'TacT3.filter.fastq', 'Ita3.filter.fastq', 'Control.filter.fastq']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import ribo_util\n",
    "import ribo_main\n",
    "import ribo_analysis\n",
    "import ribo_plot\n",
    "import ribo_coords\n",
    "\n",
    "import os\n",
    "\n",
    "# File names can be manually added to list, or read as .csv with header == Library\n",
    "# Library names must be the same as the fastq file name\n",
    "\n",
    "path_pc     = '/home/gyrase/datatank/Bikmetov/toxin_profiling/2018_Bacterial_Pipeline_riboseq-clean_first/results/'  # location of folder for ribosome profiling\n",
    "path_script = '/home/gyrase/datatank/Bikmetov/toxin_profiling/2018_Bacterial_Pipeline_riboseq-clean_first/'\n",
    "\n",
    "all_files  = [x for x in os.listdir(path_pc + '/libraries/FASTQ/')]\n",
    "file_csv   = path_script  + 'Library_names.csv'  # alternatively, provide .csv with filenames\n",
    "'''\n",
    "all_files  = []                              # sample name, same as FASTQ filename\n",
    "file_csv   = path_pc  + 'Library_names.csv'  # alternatively, provide .csv with filenames\n",
    "\n",
    "library_id = pd.read_csv(file_csv)\n",
    "\n",
    "for fname in library_id.Library:\n",
    "    all_files.append(fname)'''\n",
    "print all_files\n",
    "\n",
    "inputs = {}\n",
    "inputs['files'] = []\n",
    "inputs['multiprocess'] = 'yes'\n",
    "inputs['threads']      = 20   # CPU information for multithreading applications\n",
    "inputs['cores']        = 10\n",
    "\n",
    "paths_in = {}\n",
    "paths_in['path_gff']        = path_pc + 'annotations/Coli/Coli.gff'\n",
    "paths_in['path_gff_dict']   = path_pc + 'annotations/Coli/Coli_dict'       # this will be made from the GFF file\n",
    "paths_in['path_badgenes']   = path_pc + 'annotations/Coli/bad_genes.csv'   # list of genes to exclude\n",
    "paths_in['path_annotation'] = path_pc + 'annotations/Coli/annotation.csv'  # adds gene description to GFF_dict \n",
    "\n",
    "# Outputs from analysis will be placed in the foillowing directories:\n",
    "paths_out = {}\n",
    "paths_out['path_density']      = path_pc  + 'libraries/density/density/'  # Created from Ribo_Density\n",
    "paths_out['path_log']          = path_pc  + 'libraries/density/logs/'\n",
    "paths_out['path_analysis_log'] = path_pc  + 'libraries/analysis/logs/'\n",
    "paths_out['path_analysis']     = path_pc  + 'libraries/analysis/individual/'\n",
    "paths_out['path_figures']      = path_pc  + 'libraries/figures/'\n",
    "\n",
    "    \n",
    "# Check inputs, create output paths\n",
    "step = 'analysis'                                # density or analysis\n",
    "ribo_util.check_inputs(inputs, paths_in, step)   # will remove file from analysis for not having a density file\n",
    "ribo_util.createpath(inputs, paths_out, all_files)          # create output paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Settings\n",
    "\n",
    "Set settings values for the various analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Settings \n",
    "settings = {}\n",
    "settings['minlength'] = 15    # minimum read lenght\n",
    "settings['maxlength'] = 40    # maximum read length\n",
    "settings['shift']     = 11    # A-site shift\n",
    "settings['gff_extra'] = 50    # Number of nt added before start seq and after stop seq in GFF_dict\n",
    "settings['threshold'] = 1    # in reads per codon\n",
    "settings['alignment'] = '3'   # '3' or '5'\n",
    "\n",
    "# Avggenes Settings\n",
    "settings['length_out_ORF'] = 50\n",
    "settings['length_in_ORF']  = 100        # genes shorter than this are excluded\n",
    "settings['density_type']   = 'reads'    # 'reads' or 'rpm' \n",
    "settings['equal_weight']   = 'yes'      # 'yes' or 'no', if yes, change density_type to reads -- faster\n",
    "settings['next_gene']      = 25         # genes closer than this are removed from start and stop \n",
    "\n",
    "# Pausescore settings\n",
    "settings['A_site shift']    = -11\n",
    "settings['plot_upstream']   = 40\n",
    "settings['plot_downstream'] = 50\n",
    "settings['start_trim']      = 50\n",
    "settings['stop_trim']       = 20\n",
    "settings['frameshift']      = 0\n",
    "\n",
    "# Genelist settings\n",
    "settings['subgroup'] = 'none'\n",
    "\n",
    "# Pausescore waves settings\n",
    "settings['plot_upstream_wave']   = 106\n",
    "settings['plot_downstream_wave'] = 106\n",
    "settings['next_codon']           = 'yes'\n",
    "\n",
    "# Motif analysis\n",
    "settings['motif_length'] = 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Annotation dictionary from GFF\n",
    "\n",
    "Pipeline uses a simplified dictionary of the GFF for speed. This function will strip the GFF to the gene name, start and stop position, and sequence of the gene\n",
    "\n",
    "This needs to be run only once, so you can comment it off once it does run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff_settings = {}\n",
    "gff_settings['path_out']         = 0             # set to 0 to output in annotations folder\n",
    "gff_settings['feat_of_interest'] = 'all'         # all, CDS, tRNA, rRNA: recommend using all\n",
    "gff_settings['name_qual']        = 'Name'        # GFF gene qualifier\n",
    "gff_settings['name_qual_alt']    = 'ID'          # Secondary GFF gene qualifier if no name is present\n",
    "gff_settings['remove_genes']     = 'yes'         # remove hard to align genes listed in bad_genes.csv\n",
    "gff_settings['gff_extra']         = 50           # additional sequence upstream and downstream of gene (set to 50)\n",
    "\n",
    "#GFF_conversion = ribo_util.GFF_to_dict(paths_in, gff_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started  at 2020-01-24 16:15:16.842248\n",
      "['T62.filter.fastq', 'TacT3.filter.fastq', 'Ita3.filter.fastq', 'Control.filter.fastq']\n",
      "Started asymmetry analysis at 2020-01-24 16:17:32.802675\n",
      "42360136.0\n",
      "[7115274. 7029851. 5286136. 4618415. 3651400. 3253557. 3293794. 2854008.\n",
      " 2803412. 2454289.]\n",
      "13150128.0\n",
      "[3405642. 2448826. 1679751. 1300325.  888547.  795895.  795856.  640197.\n",
      "  600110.  594979.]\n",
      "5071904.0\n",
      "[913542. 759410. 666052. 535856. 451255. 395622. 392254. 361796. 338128.\n",
      " 257989.]\n",
      "16846500.0\n",
      "[2278037. 1905547. 1778740. 1653611. 1502624. 1618224. 1560043. 1551383.\n",
      " 1499831. 1498460.]\n",
      "Finished asymmetry analysis at 2020-01-24 16:17:42.130581\n",
      "Finished  at 2020-01-24 16:17:42.131013\n"
     ]
    }
   ],
   "source": [
    "lib_count = len(all_files)\n",
    "lib_index = 0 \n",
    "lib_runs  = 8  # limits number of samples processed, scale with RAM imitations\n",
    "\n",
    "for loops in range(0, lib_count / lib_runs + 2):\n",
    "\n",
    "    if lib_index < lib_count:\n",
    "        print \"Started  at \" + str(datetime.now())\n",
    "        if lib_count - lib_index >= lib_runs:\n",
    "            inputs['files'] = [all_files[i] for i in range(lib_index, lib_index + lib_runs)]\n",
    "\n",
    "            print inputs['files']\n",
    "            \n",
    "            if not 'gff_dict' in globals(): \n",
    "                gff_dict, plus_dict, minus_dict = ribo_util.loadlargePickles(inputs, settings, paths_in, paths_out)\n",
    "            else: \n",
    "                gff_dict, plus_dict, minus_dict = ribo_util.loadlargePickles(inputs, settings, paths_in, paths_out)\n",
    "                        \n",
    "            asymmetry_analysis = ribo_coords.asymmetry(inputs, paths_out, settings, gff_dict, plus_dict, minus_dict)\n",
    "            \n",
    "        else:\n",
    "            inputs['files'] = [all_files[i] for i in range(lib_index, lib_count)]\n",
    "            \n",
    "            print inputs['files']    \n",
    "            if not 'gff_dict' in globals(): \n",
    "                gff_dict, plus_dict, minus_dict = ribo_util.loadlargePickles(inputs, settings, paths_in, paths_out)\n",
    "            else: \n",
    "                gff_dict, plus_dict, minus_dict = ribo_util.loadlargePickles(inputs, settings, paths_in, paths_out)\n",
    "                \n",
    "            asymmetry_analysis = ribo_coords.asymmetry(inputs, paths_out, settings, gff_dict, plus_dict, minus_dict)\n",
    "            \n",
    "    else:\n",
    "        continue\n",
    "    lib_index += lib_runs  \n",
    "print \"Finished  at \" + str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy.stats.mstats import gmean\n",
    "from skbio.stats import composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['Control', 'TacT2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../Control_solo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4719f525b931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../%s_solo'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../Control_solo'"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for x in samples:\n",
    "    with open('../%s_solo' % x, 'r') as inf:\n",
    "        data[x] = pd.DataFrame.from_dict(pickle.load(inf)).T\n",
    "        index = [np.prod(y) != 0 for y in data[x][0]]\n",
    "        data[x] = data[x][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Control'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5e3d1cd69c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mboth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Control'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TacT2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Control'"
     ]
    }
   ],
   "source": [
    "both = set(data['Control'].index) & set(data['TacT2'].index)\n",
    "len(both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmeans = {}\n",
    "for x in samples:\n",
    "    df = data[x].filter(items = both, axis = 0).sort_index()[0]\n",
    "    per_cent = composition.closure(df)\n",
    "    ilr = df.apply(composition.ilr)\n",
    "    df = np.stack(df.to_numpy())\n",
    "    ilr = np.stack(ilr.to_numpy())\n",
    "    np.savetxt(\"%s_paired_raw.csv\" % x, df, delimiter=\",\")\n",
    "    np.savetxt(\"%s_paired_ilr.csv\" % x, ilr, delimiter=\",\")\n",
    "    gmeans[x] = gmean(per_cent, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gmeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9f399bd27f85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgmeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gmeans' is not defined"
     ]
    }
   ],
   "source": [
    "gmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
